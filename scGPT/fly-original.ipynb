{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/qxy699/.local/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: torchvision in /home/qxy699/.local/lib/python3.10/site-packages (0.18.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: networkx in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in /home/qxy699/.local/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/qxy699/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in /home/qxy699/.local/lib/python3.10/site-packages (from torchvision) (1.25.2)\n",
      "Collecting torch\n",
      "  Using cached torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/qxy699/.local/lib/python3.10/site-packages (from torchvision) (2.32.3)\n",
      "Collecting torch\n",
      "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in /home/qxy699/.local/lib/python3.10/site-packages (from requests->torchvision) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/qxy699/.local/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2020.6.20)\n",
      "Installing collected packages: torchvision\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.18.1\n",
      "    Uninstalling torchvision-0.18.1:\n",
      "      Successfully uninstalled torchvision-0.18.1\n",
      "Successfully installed torchvision-0.16.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from biomart import BiomartServer\n",
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import wandb\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sys.path.insert(0, \"../\")\n",
    "import scgpt as scg\n",
    "from scgpt.model import TransformerModel, AdversarialDiscriminator\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch, random_mask_value\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    masked_relative_error,\n",
    "    criterion_neg_log_bernoulli,\n",
    ")\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt import SubsetsBatchSampler\n",
    "from scgpt.utils import set_seed, category_str2int, eval_scib_metrics\n",
    "\n",
    "sc.set_figure_params(figsize=(6, 6))\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_defaults = dict(\n",
    "    seed=0,\n",
    "    dataset_name=\"fly\",\n",
    "    do_train=False,\n",
    "    load_model=\"./model.pt\",\n",
    "    mask_ratio=0.0,\n",
    "    epochs=10,\n",
    "    n_bins=51,\n",
    "    MVC=False, # Masked value prediction for cell embedding\n",
    "    ecs_thres=0.0, # Elastic cell similarity objective, 0.0 to 1.0, 0.0 to disable\n",
    "    dab_weight=0.0,\n",
    "    lr=1e-4,\n",
    "    batch_size=1,\n",
    "    layer_size=512,\n",
    "    nlayers=12,  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "    nhead=8,  # number of heads in nn.MultiheadAttention\n",
    "    dropout=0.2,  # dropout probability\n",
    "    schedule_ratio=0.9,  # ratio of epochs for learning rate schedule\n",
    "    save_eval_interval=5,\n",
    "    fast_transformer=True,\n",
    "    pre_norm=False,\n",
    "    amp=True,  # Automatic Mixed Precision\n",
    "    include_zero_gene = False,\n",
    "    freeze = False, #freeze\n",
    "    DSBN = False,  # Domain-spec batchnorm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for input and preprocessing\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "mask_ratio = hyperparameter_defaults[\"mask_ratio\"]\n",
    "mask_value = \"auto\"  # for masked values, now it should always be auto\n",
    "include_zero_gene = hyperparameter_defaults[\"include_zero_gene\"]  # if True, include zero genes among hvgs in the training\n",
    "max_seq_len = 4716\n",
    "n_bins = hyperparameter_defaults[\"n_bins\"]\n",
    "\n",
    "# input/output representation\n",
    "input_style = \"binned\"  # \"normed_raw\", \"log1p\", or \"binned\"\n",
    "output_style = \"binned\"  # \"normed_raw\", \"log1p\", or \"binned\"\n",
    "\n",
    "# settings for training\n",
    "MLM = False  # whether to use masked language modeling, currently it is always on.\n",
    "CLS = True  # classification objective\n",
    "ADV = False  # Adversarial training for batch correction\n",
    "CCE = False  # Contrastive cell embedding objective\n",
    "MVC = hyperparameter_defaults[\"MVC\"]  # Masked value prediction for cell embedding\n",
    "ECS = hyperparameter_defaults[\"ecs_thres\"] > 0  # Elastic cell similarity objective\n",
    "DAB = False  # Domain adaptation by reverse backpropagation, set to 2 for separate optimizer\n",
    "INPUT_BATCH_LABELS = False  # TODO: have these help MLM and MVC, while not to classifier\n",
    "input_emb_style = \"continuous\"  # \"category\" or \"continuous\" or \"scaling\"\n",
    "cell_emb_style = \"cls\"  # \"avg-pool\" or \"w-pool\" or \"cls\"\n",
    "adv_E_delay_epochs = 0  # delay adversarial training on encoder for a few epochs\n",
    "adv_D_delay_epochs = 0\n",
    "mvc_decoder_style = \"inner product\"\n",
    "ecs_threshold = hyperparameter_defaults[\"ecs_thres\"]\n",
    "dab_weight = hyperparameter_defaults[\"dab_weight\"]\n",
    "explicit_zero_prob = MLM and include_zero_gene  # whether explicit bernoulli for zeros\n",
    "do_sample_in_train = False and explicit_zero_prob  # sample the bernoulli in training\n",
    "per_seq_batch_sample = False\n",
    "\n",
    "# settings for optimizer\n",
    "lr = hyperparameter_defaults[\"lr\"]  # TODO: test learning rate ratio between two tasks\n",
    "lr_ADV = 1e-3  # learning rate for discriminator, used when ADV is True\n",
    "batch_size = hyperparameter_defaults[\"batch_size\"]\n",
    "eval_batch_size = hyperparameter_defaults[\"batch_size\"]\n",
    "epochs = hyperparameter_defaults[\"epochs\"]\n",
    "schedule_interval = 1\n",
    "\n",
    "# settings for the model\n",
    "fast_transformer = hyperparameter_defaults[\"fast_transformer\"]\n",
    "fast_transformer_backend = \"flash\"  # \"linear\" or \"flash\"\n",
    "embsize = hyperparameter_defaults[\"layer_size\"]  # embedding dimension\n",
    "d_hid = hyperparameter_defaults[\"layer_size\"]  # dimension of the feedforward network in TransformerEncoder\n",
    "nlayers = hyperparameter_defaults[\"nlayers\"]  # number of TransformerEncoderLayer in TransformerEncoder\n",
    "nhead = hyperparameter_defaults[\"nhead\"]  # number of heads in nn.MultiheadAttention\n",
    "dropout = hyperparameter_defaults[\"dropout\"]  # dropout probability\n",
    "\n",
    "# logging\n",
    "log_interval = 100  # iterations\n",
    "save_eval_interval = hyperparameter_defaults[\"save_eval_interval\"]  # epochs\n",
    "do_eval_scib_metrics = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% validate settings\n",
    "assert input_style in [\"normed_raw\", \"log1p\", \"binned\"]\n",
    "assert output_style in [\"normed_raw\", \"log1p\", \"binned\"]\n",
    "assert input_emb_style in [\"category\", \"continuous\", \"scaling\"]\n",
    "if input_style == \"binned\":\n",
    "    if input_emb_style == \"scaling\":\n",
    "        raise ValueError(\"input_emb_style `scaling` is not supported for binned input.\")\n",
    "elif input_style == \"log1p\" or input_style == \"normed_raw\":\n",
    "    if input_emb_style == \"category\":\n",
    "        raise ValueError(\n",
    "            \"input_emb_style `category` is not supported for log1p or normed_raw input.\"\n",
    "        )\n",
    "\n",
    "if input_emb_style == \"category\":\n",
    "    mask_value = n_bins + 1\n",
    "    pad_value = n_bins  # for padding gene expr values\n",
    "    n_input_bins = n_bins + 2\n",
    "else:\n",
    "    mask_value = -1\n",
    "    pad_value = -2\n",
    "    n_input_bins = n_bins\n",
    "\n",
    "if ADV and DAB:\n",
    "    raise ValueError(\"ADV and DAB cannot be both True.\")\n",
    "DAB_separate_optim = True if DAB > 1 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path(\"/home/phv028r/scGPT-aging/raw-data/fly\")\n",
    "adata = sc.read(\"./adata_headBody_S_v1.0.h5ad\")\n",
    "adata.obs[\"age\"] = adata.obs[\"age\"].astype(\"category\")\n",
    "adata.var[\"gene_name\"] = adata.var.index\n",
    "adata.var.set_index(adata.var[\"gene_name\"], inplace=True)\n",
    "data_is_raw = False\n",
    "filter_gene_by_counts = False\n",
    "\n",
    "ensembl_server = BiomartServer(\"http://www.ensembl.org/biomart\")\n",
    "ensembl_dataset = ensembl_server.datasets['dmelanogaster_gene_ensembl']\n",
    "ensembl_query = ensembl_dataset.search({\n",
    "#         \"filters\": {\n",
    "#             \"external_gene_name\": adata.var[\"gene_name\"].tolist(),\n",
    "#         },\n",
    "    'attributes': [\n",
    "#             'flybase_gene_id',        # Fly gene ID\n",
    "        'external_gene_name',     # Fly gene name\n",
    "        'hsapiens_homolog_ensembl_gene', # Human gene ID\n",
    "        'hsapiens_homolog_associated_gene_name' # Human gene name\n",
    "    ]\n",
    "})\n",
    "\n",
    "ensembl_query_text = ensembl_query.text\n",
    "ensembl_query_lines = ensembl_query_text.strip().split(\"\\n\")\n",
    "ensembl_query_columns = [\"fly_gene\", \"human_ensembl_id\", \"human_gene\"]\n",
    "ensembl_query_text = [line.split(\"\\t\") for line in ensembl_query_lines[1:]]\n",
    "ensembl_query_df = pd.DataFrame(ensembl_query_text, columns=ensembl_query_columns)\n",
    "ensembl_query_df['human_gene'].replace('', pd.NA, inplace=True)\n",
    "filtered_ensembl_query_df = ensembl_query_df.dropna(subset=[\"human_gene\"])\n",
    "map_fly_to_human_dict = pd.Series(filtered_ensembl_query_df.human_gene.values, index=filtered_ensembl_query_df.fly_gene).to_dict()\n",
    "reverse_mapping = dict()\n",
    "for fly_gene, human_gene in map_fly_to_human_dict.items():\n",
    "    reverse_mapping[human_gene] = fly_gene\n",
    "reverse_mapping.pop(\"AGO2\")\n",
    "reverse_mapping.pop(\"PCNA\")\n",
    "reverse_mapping.pop(\"SPR\")\n",
    "reverse_mapping.pop(\"PGAP2\")\n",
    "reverse_mapping.pop(\"MED22\")\n",
    "one_to_one_mapping = {v: k for k, v in reverse_mapping.items()}\n",
    "new_index = []\n",
    "for gene in adata.var.index:\n",
    "    if gene in one_to_one_mapping:\n",
    "        new_index.append(one_to_one_mapping[gene])\n",
    "    else:\n",
    "        new_index.append(gene)\n",
    "adata.var.index = pd.Index(new_index)\n",
    "\n",
    "\n",
    "# make the batch category column\n",
    "age_id_labels = adata.obs[\"age\"].astype(\"category\").cat.codes.values\n",
    "ages = adata.obs[\"age\"].unique()\n",
    "num_types = len(np.unique(age_id_labels))\n",
    "id2type = dict(enumerate(adata.obs[\"age\"].astype(\"category\").cat.categories))\n",
    "adata.obs[\"age_id\"] = age_id_labels\n",
    "adata.var[\"gene_name\"] = adata.var.index.tolist()\n",
    "\n",
    "# randomly sample cells\n",
    "sampled_indices = []\n",
    "for age_category in ages:\n",
    "    age_group = adata.obs[adata.obs['age'] == age_category]\n",
    "    sampled_group = age_group.sample(n=250, random_state=42)\n",
    "    sampled_indices.extend(sampled_group.index)\n",
    "adata = adata[sampled_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match 4715/15992 genes in vocabulary of size 60697.\n"
     ]
    }
   ],
   "source": [
    "# model_dir = Path(hyperparameter_defaults[\"load_model\"])\n",
    "model_file = \"./model.pt\"\n",
    "vocab_file = \"./vocab.json\"\n",
    "vocab = GeneVocab.from_file(vocab_file)\n",
    "for s in special_tokens:\n",
    "    if s not in vocab:\n",
    "        vocab.append_token(s)\n",
    "\n",
    "adata.var[\"id_in_vocab\"] = [\n",
    "    1 if gene in vocab else -1 for gene in adata.var[\"gene_name\"]\n",
    "]\n",
    "gene_ids_in_vocab = np.array(adata.var[\"id_in_vocab\"])\n",
    "print(\n",
    "    f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "    f\"in vocabulary of size {len(vocab)}.\"\n",
    ")\n",
    "\n",
    "adata = adata[:, adata.var[\"id_in_vocab\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import issparse\n",
    "import scanpy as sc\n",
    "from scanpy.get import _get_obs_rep, _set_obs_rep\n",
    "from anndata import AnnData\n",
    "\n",
    "from scgpt import logger\n",
    "\n",
    "\n",
    "class Preprocessor_Edit:\n",
    "    \"\"\"\n",
    "    Prepare data into training, valid and test split. Normalize raw expression\n",
    "    values, binning or using other transform into the preset model input format.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_key: Optional[str] = None,\n",
    "        filter_gene_by_counts: Union[int, bool] = False,\n",
    "        filter_cell_by_counts: Union[int, bool] = False,\n",
    "        normalize_total: Union[float, bool] = 1e4,\n",
    "        result_normed_key: Optional[str] = \"X_normed\",\n",
    "        log1p: bool = False,\n",
    "        result_log1p_key: str = \"X_log1p\",\n",
    "        subset_hvg: Union[int, bool] = False,\n",
    "        hvg_use_key: Optional[str] = None,\n",
    "        hvg_flavor: str = \"seurat_v3\",\n",
    "        binning: Optional[int] = None,\n",
    "        result_binned_key: str = \"X_binned\",\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        Set up the preprocessor, use the args to config the workflow steps.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        use_key (:class:`str`, optional):\n",
    "            The key of :class:`~anndata.AnnData` to use for preprocessing.\n",
    "        filter_gene_by_counts (:class:`int` or :class:`bool`, default: ``False``):\n",
    "            Whther to filter genes by counts, if :class:`int`, filter genes with counts\n",
    "        filter_cell_by_counts (:class:`int` or :class:`bool`, default: ``False``):\n",
    "            Whther to filter cells by counts, if :class:`int`, filter cells with counts\n",
    "        normalize_total (:class:`float` or :class:`bool`, default: ``1e4``):\n",
    "            Whether to normalize the total counts of each cell to a specific value.\n",
    "        result_normed_key (:class:`str`, default: ``\"X_normed\"``):\n",
    "            The key of :class:`~anndata.AnnData` to store the normalized data. If\n",
    "            :class:`None`, will use normed data to replce the :attr:`use_key`.\n",
    "        log1p (:class:`bool`, default: ``True``):\n",
    "            Whether to apply log1p transform to the normalized data.\n",
    "        result_log1p_key (:class:`str`, default: ``\"X_log1p\"``):\n",
    "            The key of :class:`~anndata.AnnData` to store the log1p transformed data.\n",
    "        subset_hvg (:class:`int` or :class:`bool`, default: ``False``):\n",
    "            Whether to subset highly variable genes.\n",
    "        hvg_use_key (:class:`str`, optional):\n",
    "            The key of :class:`~anndata.AnnData` to use for calculating highly variable\n",
    "            genes. If :class:`None`, will use :attr:`adata.X`.\n",
    "        hvg_flavor (:class:`str`, default: ``\"seurat_v3\"``):\n",
    "            The flavor of highly variable genes selection. See\n",
    "            :func:`scanpy.pp.highly_variable_genes` for more details.\n",
    "        binning (:class:`int`, optional):\n",
    "            Whether to bin the data into discrete values of number of bins provided.\n",
    "        result_binned_key (:class:`str`, default: ``\"X_binned\"``):\n",
    "            The key of :class:`~anndata.AnnData` to store the binned data.\n",
    "        \"\"\"\n",
    "        self.use_key = use_key\n",
    "        self.filter_gene_by_counts = filter_gene_by_counts\n",
    "        self.filter_cell_by_counts = filter_cell_by_counts\n",
    "        self.normalize_total = normalize_total\n",
    "        self.result_normed_key = result_normed_key\n",
    "        self.log1p = log1p\n",
    "        self.result_log1p_key = result_log1p_key\n",
    "        self.subset_hvg = subset_hvg\n",
    "        self.hvg_use_key = hvg_use_key\n",
    "        self.hvg_flavor = hvg_flavor\n",
    "        self.binning = binning\n",
    "        self.result_binned_key = result_binned_key\n",
    "\n",
    "    def __call__(self, adata: AnnData, batch_key: Optional[str] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        format controls the different input value wrapping, including categorical\n",
    "        binned style, fixed-sum normalized counts, log1p fixed-sum normalized counts, etc.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        adata (:class:`AnnData`):\n",
    "            The :class:`AnnData` object to preprocess.\n",
    "        batch_key (:class:`str`, optional):\n",
    "            The key of :class:`AnnData.obs` to use for batch information. This arg\n",
    "            is used in the highly variable gene selection step.\n",
    "        \"\"\"\n",
    "        key_to_process = self.use_key\n",
    "        # preliminary checks, will use later\n",
    "        if key_to_process == \"X\":\n",
    "            key_to_process = None  # the following scanpy apis use arg None to use X\n",
    "        is_logged = self.check_logged(adata, obs_key=key_to_process)\n",
    "\n",
    "        # step 1: filter genes\n",
    "        if self.filter_gene_by_counts:\n",
    "            logger.info(\"Filtering genes by counts ...\")\n",
    "            sc.pp.filter_genes(\n",
    "                adata,\n",
    "                min_counts=self.filter_gene_by_counts\n",
    "                if isinstance(self.filter_gene_by_counts, int)\n",
    "                else None,\n",
    "            )\n",
    "\n",
    "        # step 2: filter cells\n",
    "        if (\n",
    "            isinstance(self.filter_cell_by_counts, int)\n",
    "            and self.filter_cell_by_counts > 0\n",
    "        ):\n",
    "            logger.info(\"Filtering cells by counts ...\")\n",
    "            sc.pp.filter_cells(\n",
    "                adata,\n",
    "                min_counts=self.filter_cell_by_counts\n",
    "                if isinstance(self.filter_cell_by_counts, int)\n",
    "                else None,\n",
    "            )\n",
    "\n",
    "        # step 3: normalize total\n",
    "        if self.normalize_total:\n",
    "            logger.info(\"Normalizing total counts ...\")\n",
    "            normed_ = sc.pp.normalize_total(\n",
    "                adata,\n",
    "                target_sum=self.normalize_total\n",
    "                if isinstance(self.normalize_total, float)\n",
    "                else None,\n",
    "                layer=key_to_process,\n",
    "                inplace=False,\n",
    "            )[\"X\"]\n",
    "            key_to_process = self.result_normed_key or key_to_process\n",
    "            _set_obs_rep(adata, normed_, layer=key_to_process)\n",
    "\n",
    "        # step 4: log1p\n",
    "        if self.log1p:\n",
    "            logger.info(\"Log1p transforming ...\")\n",
    "            if is_logged:\n",
    "                logger.warning(\n",
    "                    \"The input data seems to be already log1p transformed. \"\n",
    "                    \"Set `log1p=False` to avoid double log1p transform.\"\n",
    "                )\n",
    "            if self.result_log1p_key:\n",
    "                _set_obs_rep(\n",
    "                    adata,\n",
    "                    _get_obs_rep(adata, layer=key_to_process),\n",
    "                    layer=self.result_log1p_key,\n",
    "                )\n",
    "                key_to_process = self.result_log1p_key\n",
    "            sc.pp.log1p(adata, layer=key_to_process)\n",
    "\n",
    "        # step 5: subset hvg\n",
    "        if self.subset_hvg:\n",
    "            logger.info(\"Subsetting highly variable genes ...\")\n",
    "            if batch_key is None:\n",
    "                logger.warning(\n",
    "                    \"No batch_key is provided, will use all cells for HVG selection.\"\n",
    "                )\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata,\n",
    "                layer=self.hvg_use_key,\n",
    "                n_top_genes=self.subset_hvg\n",
    "                if isinstance(self.subset_hvg, int)\n",
    "                else None,\n",
    "                batch_key=batch_key,\n",
    "                flavor=self.hvg_flavor,\n",
    "                subset=True,\n",
    "            )\n",
    "\n",
    "        # step 6: binning\n",
    "        if self.binning:\n",
    "            logger.info(\"Binning data ...\")\n",
    "            if not isinstance(self.binning, int):\n",
    "                raise ValueError(\n",
    "                    \"Binning arg must be an integer, but got {}.\".format(self.binning)\n",
    "                )\n",
    "            n_bins = self.binning  # NOTE: the first bin is always a spectial for zero\n",
    "            binned_rows = []\n",
    "            bin_edges = []\n",
    "            layer_data = _get_obs_rep(adata, layer=key_to_process)\n",
    "            layer_data = layer_data.toarray() if issparse(layer_data) else layer_data\n",
    "            if layer_data.min() < 0:\n",
    "                raise ValueError(\n",
    "                    f\"Assuming non-negative data, but got min value {layer_data.min()}.\"\n",
    "                )\n",
    "            for row in layer_data:\n",
    "                if row.max() == 0:\n",
    "                    logger.warning(\n",
    "                        \"The input data contains all zero rows. Please make sure \"\n",
    "                        \"this is expected. You can use the `filter_cell_by_counts` \"\n",
    "                        \"arg to filter out all zero rows.\"\n",
    "                    )\n",
    "                    binned_rows.append(np.zeros_like(row, dtype=np.int64))\n",
    "                    bin_edges.append(np.array([0] * n_bins))\n",
    "                    continue\n",
    "                non_zero_ids = row.nonzero()\n",
    "                non_zero_row = row[non_zero_ids]\n",
    "                bins = np.quantile(non_zero_row, np.linspace(0, 1, n_bins - 1))\n",
    "                # bins = np.sort(np.unique(bins))\n",
    "                # NOTE: comment this line for now, since this will make the each category\n",
    "                # has different relative meaning across datasets\n",
    "                non_zero_digits = _digitize(non_zero_row, bins)\n",
    "                assert non_zero_digits.min() >= 1\n",
    "                assert non_zero_digits.max() <= n_bins - 1\n",
    "                binned_row = np.zeros_like(row, dtype=np.int64)\n",
    "                binned_row[non_zero_ids] = non_zero_digits\n",
    "                binned_rows.append(binned_row)\n",
    "                bin_edges.append(np.concatenate([[0], bins]))\n",
    "            adata.layers[self.result_binned_key] = np.stack(binned_rows)\n",
    "            adata.obsm[\"bin_edges\"] = np.stack(bin_edges)\n",
    "\n",
    "    def check_logged(self, adata: AnnData, obs_key: Optional[str] = None) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the data is already log1p transformed.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        adata (:class:`AnnData`):\n",
    "            The :class:`AnnData` object to preprocess.\n",
    "        obs_key (:class:`str`, optional):\n",
    "            The key of :class:`AnnData.obs` to use for batch information. This arg\n",
    "            is used in the highly variable gene selection step.\n",
    "        \"\"\"\n",
    "        data = _get_obs_rep(adata, layer=obs_key)\n",
    "        max_, min_ = data.max(), data.min()\n",
    "        if max_ > 30:\n",
    "            return False\n",
    "        if min_ < 0:\n",
    "            return False\n",
    "\n",
    "        non_zero_min = data[data > 0].min()\n",
    "        if non_zero_min >= 1:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "def _digitize(x: np.ndarray, bins: np.ndarray, side=\"both\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Digitize the data into bins. This method spreads data uniformly when bins\n",
    "    have same values.\n",
    "\n",
    "    Args:\n",
    "\n",
    "    x (:class:`np.ndarray`):\n",
    "        The data to digitize.\n",
    "    bins (:class:`np.ndarray`):\n",
    "        The bins to use for digitization, in increasing order.\n",
    "    side (:class:`str`, optional):\n",
    "        The side to use for digitization. If \"one\", the left side is used. If\n",
    "        \"both\", the left and right side are used. Default to \"one\".\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    :class:`np.ndarray`:\n",
    "        The digitized data.\n",
    "    \"\"\"\n",
    "    assert x.ndim == 1 and bins.ndim == 1\n",
    "\n",
    "    left_digits = np.digitize(x, bins)\n",
    "    if side == \"one\":\n",
    "        return left_digits\n",
    "\n",
    "    right_difits = np.digitize(x, bins, right=True)\n",
    "\n",
    "    rands = np.random.rand(len(x))  # uniform random numbers\n",
    "\n",
    "    digits = rands * (right_difits - left_digits) + left_digits\n",
    "    digits = np.ceil(digits).astype(np.int64)\n",
    "    return digits\n",
    "\n",
    "\n",
    "def binning(\n",
    "    row: Union[np.ndarray, torch.Tensor], n_bins: int\n",
    ") -> Union[np.ndarray, torch.Tensor]:\n",
    "    \"\"\"Binning the row into n_bins.\"\"\"\n",
    "    dtype = row.dtype\n",
    "    return_np = False if isinstance(row, torch.Tensor) else True\n",
    "    row = row.cpu().numpy() if isinstance(row, torch.Tensor) else row\n",
    "    # TODO: use torch.quantile and torch.bucketize\n",
    "\n",
    "    if row.max() == 0:\n",
    "        logger.warning(\n",
    "            \"The input data contains row of zeros. Please make sure this is expected.\"\n",
    "        )\n",
    "        return (\n",
    "            np.zeros_like(row, dtype=dtype)\n",
    "            if return_np\n",
    "            else torch.zeros_like(row, dtype=dtype)\n",
    "        )\n",
    "\n",
    "    if row.min() <= 0:\n",
    "        non_zero_ids = row.nonzero()\n",
    "        non_zero_row = row[non_zero_ids]\n",
    "        bins = np.quantile(non_zero_row, np.linspace(0, 1, n_bins - 1))\n",
    "        non_zero_digits = _digitize(non_zero_row, bins)\n",
    "        binned_row = np.zeros_like(row, dtype=np.int64)\n",
    "        binned_row[non_zero_ids] = non_zero_digits\n",
    "    else:\n",
    "        bins = np.quantile(row, np.linspace(0, 1, n_bins - 1))\n",
    "        binned_row = _digitize(row, bins)\n",
    "    return torch.from_numpy(binned_row) if not return_np else binned_row.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Binning data ...\n"
     ]
    }
   ],
   "source": [
    "# set up the preprocessor, use the args to config the workflow\n",
    "preprocessor = Preprocessor_Edit(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=filter_gene_by_counts,  # step 1\n",
    "    filter_cell_by_counts=False,  # step 2\n",
    "    normalize_total=False,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=data_is_raw,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=False,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    binning=n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "\n",
    "# Preprocess training and testing data\n",
    "preprocessor(adata, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_key = {  # the values of this map coorespond to the keys in preprocessing\n",
    "    \"normed_raw\": \"X_normed\",\n",
    "    \"log1p\": \"X_normed\",\n",
    "    \"binned\": \"X_binned\",\n",
    "}[input_style]\n",
    "all_counts = (\n",
    "    adata.layers[input_layer_key].A\n",
    "    if issparse(adata.layers[input_layer_key])\n",
    "    else adata.layers[input_layer_key]\n",
    ")\n",
    "genes = adata.var[\"gene_name\"].tolist()\n",
    "\n",
    "age_labels = adata.obs[\"age_id\"].tolist()  # make sure count from 0\n",
    "age_labels = np.array(age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "gene_ids = np.array(vocab(genes), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set number of samples: 1000, \n",
      "\t feature length: 2837\n"
     ]
    }
   ],
   "source": [
    "tokenized_data = tokenize_and_pad_batch(\n",
    "    all_counts,\n",
    "    gene_ids,\n",
    "    max_len=max_seq_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    append_cls=True,  # append <cls> token at the beginning\n",
    "    include_zero_gene=include_zero_gene,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"data set number of samples: {tokenized_data['genes'].shape[0]}, \"\n",
    "    f\"\\n\\t feature length: {tokenized_data['genes'].shape[1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data: Dict[str, torch.Tensor]):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[\"gene_ids\"].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.data.items()}\n",
    "\n",
    "\n",
    "# data_loader\n",
    "def prepare_dataloader(\n",
    "    data_pt: Dict[str, torch.Tensor],\n",
    "    batch_size: int,\n",
    "    shuffle: bool = False,\n",
    "    intra_domain_shuffle: bool = False,\n",
    "    drop_last: bool = False,\n",
    "    num_workers: int = 0,\n",
    ") -> DataLoader:\n",
    "    if num_workers == 0:\n",
    "        num_workers = min(len(os.sched_getaffinity(0)), batch_size // 2)\n",
    "\n",
    "    dataset = SeqDataset(data_pt)\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "def prepare_data(tokenized_data_dxe, sort_seq_batch=False) -> Tuple[Dict[str, torch.Tensor]]:\n",
    "    masked_values = random_mask_value(\n",
    "        tokenized_data_dxe[\"values\"],\n",
    "        mask_ratio=mask_ratio,\n",
    "        mask_value=mask_value,\n",
    "        pad_value=pad_value,\n",
    "    )\n",
    "    \n",
    "    input_gene_ids = tokenized_data_dxe[\"genes\"]\n",
    "    input_values = masked_values\n",
    "    target_values = tokenized_data_dxe[\"values\"]\n",
    "    tensor_age_labels = torch.from_numpy(age_labels).long()\n",
    "\n",
    "    data_pt = {\n",
    "        \"gene_ids\": input_gene_ids,\n",
    "        \"values\": input_values,\n",
    "        \"target_values\": target_values,\n",
    "    }\n",
    "\n",
    "    return data_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available: True\n",
      "Loading all model params from ./model.pt\n",
      "--------------------\n",
      "name: encoder.embedding.weight\n",
      "--------------------\n",
      "name: encoder.enc_norm.weight\n",
      "--------------------\n",
      "name: encoder.enc_norm.bias\n",
      "--------------------\n",
      "name: value_encoder.linear1.weight\n",
      "--------------------\n",
      "name: value_encoder.linear1.bias\n",
      "--------------------\n",
      "name: value_encoder.linear2.weight\n",
      "--------------------\n",
      "name: value_encoder.linear2.bias\n",
      "--------------------\n",
      "name: value_encoder.norm.weight\n",
      "--------------------\n",
      "name: value_encoder.norm.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.norm2.bias\n",
      "--------------------\n",
      "name: decoder.fc.0.weight\n",
      "--------------------\n",
      "name: decoder.fc.0.bias\n",
      "--------------------\n",
      "name: decoder.fc.2.weight\n",
      "--------------------\n",
      "name: decoder.fc.2.bias\n",
      "--------------------\n",
      "name: decoder.fc.4.weight\n",
      "--------------------\n",
      "name: decoder.fc.4.bias\n",
      "--------------------\n",
      "name: cls_decoder._decoder.0.weight\n",
      "--------------------\n",
      "name: cls_decoder._decoder.0.bias\n",
      "--------------------\n",
      "name: cls_decoder._decoder.2.weight\n",
      "--------------------\n",
      "name: cls_decoder._decoder.2.bias\n",
      "--------------------\n",
      "name: cls_decoder._decoder.3.weight\n",
      "--------------------\n",
      "name: cls_decoder._decoder.3.bias\n",
      "--------------------\n",
      "name: cls_decoder._decoder.5.weight\n",
      "--------------------\n",
      "name: cls_decoder._decoder.5.bias\n",
      "--------------------\n",
      "name: cls_decoder.out_layer.weight\n",
      "--------------------\n",
      "name: cls_decoder.out_layer.bias\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cuda is available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerModel(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid,\n",
    "    nlayers,\n",
    "    nlayers_cls=3,\n",
    "    n_cls=num_types if CLS else 1,\n",
    "    vocab=vocab,\n",
    "    dropout=dropout,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    do_mvc=MVC,\n",
    "    do_dab=DAB,\n",
    "    use_batch_labels=INPUT_BATCH_LABELS,\n",
    "    num_batch_labels=None,\n",
    "    domain_spec_batchnorm=hyperparameter_defaults[\"DSBN\"],\n",
    "    input_emb_style=input_emb_style,\n",
    "    n_input_bins=n_input_bins,\n",
    "    cell_emb_style=cell_emb_style,\n",
    "    mvc_decoder_style=mvc_decoder_style,\n",
    "    ecs_threshold=ecs_threshold,\n",
    "    explicit_zero_prob=explicit_zero_prob,\n",
    "    use_fast_transformer=fast_transformer,\n",
    "    fast_transformer_backend=fast_transformer_backend,\n",
    "    pre_norm=hyperparameter_defaults[\"pre_norm\"],\n",
    ")\n",
    "if hyperparameter_defaults[\"load_model\"] is not None:\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_file, map_location=device))\n",
    "        print(f\"Loading all model params from {model_file}\")\n",
    "    except:\n",
    "        # only load params that are in the model and match the size\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = torch.load(model_file, map_location=device)\n",
    "        pretrained_dict = {\n",
    "            k: v\n",
    "            for k, v in pretrained_dict.items()\n",
    "            if k in model_dict and v.shape == model_dict[k].shape\n",
    "        }\n",
    "        for k, v in pretrained_dict.items():\n",
    "            print(f\"Loading params {k} with shape {v.shape}\")\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "\n",
    "pre_freeze_param_count = sum(dict((p.data_ptr(), p.numel()) for p in model.parameters() if p.requires_grad).values())\n",
    "\n",
    "# Freeze all pre-decoder weights\n",
    "for name, para in model.named_parameters():\n",
    "    print(\"-\"*20)\n",
    "    print(f\"name: {name}\")\n",
    "    if hyperparameter_defaults[\"freeze\"] and \"encoder\" in name and \"transformer_encoder\" not in name:\n",
    "        print(f\"freezing weights for: {name}\")\n",
    "        para.requires_grad = False\n",
    "\n",
    "post_freeze_param_count = sum(dict((p.data_ptr(), p.numel()) for p in model.parameters() if p.requires_grad).values())\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "if ADV:\n",
    "    discriminator = AdversarialDiscriminator(\n",
    "        d_model=embsize,\n",
    "        n_cls=num_batch_types,\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
